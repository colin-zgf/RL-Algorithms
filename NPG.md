# NPG Algorithm (Proposed in 2002)

## Background

Vanilla Policy Gradient faces challenges including bad sample efficiency and poor convergence. 

- Sample efficiency measures the amount of samples needed to improve a policy. For simulation in the real world, sampling can be expensive.

- Convergence is about whether the policy will converge to an optimal policy.
